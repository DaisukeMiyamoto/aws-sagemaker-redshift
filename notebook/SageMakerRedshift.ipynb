{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon SageMakerとAmazon Redshiftを利用し、大規模データセット対し高速・柔軟・セキュアにデータ分析を行う方法\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "必要な Python Package をインポートします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import psycopg2\n",
    "import boto3\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AWS CloudFormation で設定したパラメータを取得します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Please edit stack name\n",
    "stack_name = 'SageMakerRedshift2'\n",
    "\n",
    "cfn = boto3.client('cloudformation')\n",
    "response = cfn.describe_stacks(StackName=stack_name)['Stacks'][0]\n",
    "\n",
    "for item in response['Parameters']:\n",
    "    if item['ParameterKey'] == 'MasterUsername':\n",
    "        db_user = item['ParameterValue']\n",
    "    elif item['ParameterKey'] == 'DatabaseName':\n",
    "        db_name = item['ParameterValue']\n",
    "    elif item['ParameterKey'] == 'PortNumber':\n",
    "        db_port = item['ParameterValue']\n",
    "        \n",
    "for item in response['Outputs']:\n",
    "    if item['OutputKey'] == 'ClusterEndpoint':\n",
    "        cluster_endpoint = item['OutputValue'].split(':')[0]\n",
    "    elif item['OutputKey'] == 'ClusterName':\n",
    "        cluster_name = item['OutputValue']\n",
    "    elif item['OutputKey'] == 'RedshiftBucketAccessRoleArn':\n",
    "        redshift_role = item['OutputValue']\n",
    "        \n",
    "#  show parameters\n",
    "print('stack_name: {}'.format(stack_name))\n",
    "print('db_user: {}'.format(db_user))\n",
    "print('db_name: {}'.format(db_name))\n",
    "print('db_port: {}'.format(db_port))\n",
    "print('cluster_endpoint: {}'.format(cluster_endpoint))\n",
    "print('cluster_name: {}'.format(cluster_name))\n",
    "print('redshift_role: {}'.format(redshift_role))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon Redshift へアクセスするための、[一時的データベースユーザー認証情報](https://docs.aws.amazon.com/ja_jp/redshift/latest/mgmt/generating-iam-credentials-cli-api.html)\n",
    "を取得します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get temporal cluster credentials\n",
    "redshift = boto3.client('redshift')\n",
    "credentials = redshift.get_cluster_credentials(\n",
    "    DbUser=db_user, \n",
    "    DbName=db_name, \n",
    "    ClusterIdentifier=cluster_name, \n",
    "    DurationSeconds=3600,\n",
    "    AutoCreate=False\n",
    ")\n",
    "\n",
    "tmp_db_user = credentials['DbUser']\n",
    "tmp_db_password = credentials['DbPassword']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python用のPostgreSQLドライバであるpsycopg2を利用してRedshiftへアクセスします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to Redshift\n",
    "conn = psycopg2.connect(\n",
    "    host=cluster_endpoint, \n",
    "    port=db_port, \n",
    "    dbname=db_name, \n",
    "    user=tmp_db_user, \n",
    "    password=tmp_db_password\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここでは、公式ドキュメントで利用されているデータセットを使用します。\n",
    "https://docs.aws.amazon.com/ja_jp/redshift/latest/gsg/rs-gsg-create-sample-db.html\n",
    "\n",
    "はじめにテーブルを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_create_table = [\n",
    "    \"\"\"\n",
    "    create table users(\n",
    "        userid integer not null distkey sortkey,\n",
    "        username char(8),\n",
    "        firstname varchar(30),\n",
    "        lastname varchar(30),\n",
    "        city varchar(30),\n",
    "        state char(2),\n",
    "        email varchar(100),\n",
    "        phone char(14),\n",
    "        likesports boolean,\n",
    "        liketheatre boolean,\n",
    "        likeconcerts boolean,\n",
    "        likejazz boolean,\n",
    "        likeclassical boolean,\n",
    "        likeopera boolean,\n",
    "        likerock boolean,\n",
    "        likevegas boolean,\n",
    "        likebroadway boolean,\n",
    "        likemusicals boolean);\n",
    "    \"\"\", \n",
    "    \"\"\"\n",
    "    create table venue(\n",
    "        venueid smallint not null distkey sortkey,\n",
    "        venuename varchar(100),\n",
    "        venuecity varchar(30),\n",
    "        venuestate char(2),\n",
    "        venueseats integer);\n",
    "    \"\"\", \n",
    "    \"\"\"\n",
    "    create table category(\n",
    "        catid smallint not null distkey sortkey,\n",
    "        catgroup varchar(10),\n",
    "        catname varchar(10),\n",
    "        catdesc varchar(50));\n",
    "    \"\"\", \n",
    "    \"\"\"\n",
    "    create table date(\n",
    "        dateid smallint not null distkey sortkey,\n",
    "        caldate date not null,\n",
    "        day character(3) not null,\n",
    "        week smallint not null,\n",
    "        month character(5) not null,\n",
    "        qtr character(5) not null,\n",
    "        year smallint not null,\n",
    "        holiday boolean default('N'));\n",
    "    \"\"\", \n",
    "    \"\"\"\n",
    "    create table event(\n",
    "        eventid integer not null distkey,\n",
    "        venueid smallint not null,\n",
    "        catid smallint not null,\n",
    "        dateid smallint not null sortkey,\n",
    "        eventname varchar(200),\n",
    "        starttime timestamp);\n",
    "    \"\"\", \n",
    "    \"\"\"\n",
    "    create table listing(\n",
    "        listid integer not null distkey,\n",
    "        sellerid integer not null,\n",
    "        eventid integer not null,\n",
    "        dateid smallint not null  sortkey,\n",
    "        numtickets smallint not null,\n",
    "        priceperticket decimal(8,2),\n",
    "        totalprice decimal(8,2),\n",
    "        listtime timestamp);\n",
    "    \"\"\", \n",
    "    \"\"\"\n",
    "    create table sales(\n",
    "        salesid integer not null,\n",
    "        listid integer not null distkey,\n",
    "        sellerid integer not null,\n",
    "        buyerid integer not null,\n",
    "        eventid integer not null,\n",
    "        dateid smallint not null sortkey,\n",
    "        qtysold smallint not null,\n",
    "        pricepaid decimal(8,2),\n",
    "        commission decimal(8,2),\n",
    "        saletime timestamp);\n",
    "    \"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with conn.cursor() as cur:\n",
    "    for sql in sql_create_table:\n",
    "        cur.execute(sql)\n",
    "        print('Done: ', sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次にCOPYコマンドを利用しS3からデータをロードします。\n",
    "\n",
    "COPYコマンドを実行する場合は、クラスターが S3 のオブジェクトにアクセスするために必要な認証情報を提供する必要があります。ここでは推奨の認証方法であるIAM Roleでの認証を行っています。詳細については\n",
    "「[IAM ロールを使用して COPY、UNLOAD、および CREATE EXTERNAL SCHEMA オペレーションを承認する](https://docs.aws.amazon.com/ja_jp/redshift/latest/mgmt/copy-unload-iam-role.html)」をご参照下さい。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_copy=[\n",
    "    \"\"\"\n",
    "    copy users from 's3://awssampledbuswest2/tickit/allusers_pipe.txt' \n",
    "    credentials 'aws_iam_role={}' \n",
    "    delimiter '|' region 'us-west-2';\n",
    "    \"\"\", \n",
    "    \"\"\"\n",
    "    copy venue from 's3://awssampledbuswest2/tickit/venue_pipe.txt' \n",
    "    credentials 'aws_iam_role={}' \n",
    "    delimiter '|' region 'us-west-2';\n",
    "    \"\"\", \n",
    "    \"\"\"\n",
    "    copy category from 's3://awssampledbuswest2/tickit/category_pipe.txt' \n",
    "    credentials 'aws_iam_role={}' \n",
    "    delimiter '|' region 'us-west-2';\n",
    "    \"\"\", \n",
    "    \"\"\"\n",
    "    copy date from 's3://awssampledbuswest2/tickit/date2008_pipe.txt' \n",
    "    credentials 'aws_iam_role={}' \n",
    "    delimiter '|' region 'us-west-2';\n",
    "    \"\"\", \n",
    "    \"\"\"\n",
    "    copy event from 's3://awssampledbuswest2/tickit/allevents_pipe.txt' \n",
    "    credentials 'aws_iam_role={}' \n",
    "    delimiter '|' timeformat 'YYYY-MM-DD HH:MI:SS' region 'us-west-2';\n",
    "    \"\"\", \n",
    "    \"\"\"\n",
    "    copy listing from 's3://awssampledbuswest2/tickit/listings_pipe.txt' \n",
    "    credentials 'aws_iam_role={}' \n",
    "    delimiter '|' region 'us-west-2';\n",
    "    \"\"\", \n",
    "    \"\"\"\n",
    "    copy sales from 's3://awssampledbuswest2/tickit/sales_tab.txt'\n",
    "    credentials 'aws_iam_role={}'\n",
    "    delimiter '\\t' timeformat 'MM/DD/YYYY HH:MI:SS' region 'us-west-2';\n",
    "    \"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "with conn.cursor() as cur:\n",
    "    for sql in sql_copy:\n",
    "        cur.execute(sql.format(redshift_role))\n",
    "        print('Done: ', sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQLクエリを実行し、一部の必要なデータのみをpandasのDataFrameに格納します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get definition for the sales table.\n",
    "sql=\"\"\"\n",
    "SELECT *    \n",
    "FROM pg_table_def    \n",
    "WHERE tablename = 'sales';\n",
    "\"\"\"\n",
    "%time pd.read_sql(sql=sql, con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find total sales on a given calendar date.\n",
    "sql=\"\"\"\n",
    "SELECT sum(qtysold) \n",
    "FROM   sales, date \n",
    "WHERE  sales.dateid = date.dateid \n",
    "AND    caldate = '2008-01-05';\n",
    "\"\"\"\n",
    "%time pd.read_sql(sql=sql, con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find top 10 buyers by quantity.\n",
    "sql=\"\"\"\n",
    "SELECT firstname, lastname, total_quantity \n",
    "FROM   (SELECT buyerid, sum(qtysold) total_quantity\n",
    "        FROM  sales\n",
    "        GROUP BY buyerid\n",
    "        ORDER BY total_quantity desc limit 10) Q, users\n",
    "WHERE Q.buyerid = userid\n",
    "ORDER BY Q.total_quantity desc;\n",
    "\"\"\"\n",
    "%time df = pd.read_sql(sql=sql, con=conn)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find events in the 99.9 percentile in terms of all time gross sales.\n",
    "sql=\"\"\"\n",
    "SELECT eventname, total_price \n",
    "FROM  (SELECT eventid, total_price, ntile(1000) over(order by total_price desc) as percentile \n",
    "       FROM (SELECT eventid, sum(pricepaid) total_price\n",
    "             FROM   sales\n",
    "             GROUP BY eventid)) Q, event E\n",
    "       WHERE Q.eventid = E.eventid\n",
    "       AND percentile = 1\n",
    "ORDER BY total_price desc;\n",
    "\"\"\"\n",
    "%time df = pd.read_sql(sql=sql, con=conn)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrameを可視化します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.total_price.hist()\n",
    "plt.xlabel('Total price')\n",
    "plt.ylabel('Histogram')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最後に、psycopg2のconnectionを閉じます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
